# -*- coding: utf-8 -*-
"""classification.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/11J48T_SNvgRwYSu9C8mWGzWk13Pd8-c8
"""

# Import modules
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns



df_train = pd.read_csv('train.csv')

df_test = pd.read_csv('test.csv')

df_train.head()

df_train.columns

df_train.shape

"""Please read about pandas top functions and variables"""

df_test.head()

df_test.shape

df_test.columns

sns.countplot(x='Survived', data=df_train)

sns.catplot(x='Survived', col='Sex', kind='count', data=df_train)

# % Female Survived in Female and over Sex

sns.catplot(x='Survived', col='Sex', kind='count', data=df_train)

sns.catplot(x='Survived', col='Sex',hue='Pclass', kind='count', data=df_train)

"""#learn sns plots options"""

sns.catplot(
    x='Survived',
    col='Embarked',
    kind='count',
    data=df_train
)

sns.heatmap(pd.crosstab(df_train['Sex'], df_train['Pclass']), annot=True,fmt='d')

#Read about cross tab

sns.histplot(df_train['Age'])

df_train.describe()

sns.histplot(df_train['Fare'])

sns.boxplot(df_train['Age'])

sns.boxplot(df_train['Fare'])

sns.scatterplot(x='Age', y='Fare', hue='Survived', data=df_train)

sns.lmplot(x='Age', y='Fare', hue='Survived',line_kws={'visible': False}, data=df_train)

sns.jointplot(x='Age', y='Fare', data=df_train)

sns.boxplot(x='Pclass', y='Age', data=df_train)

sns.violinplot(x='Sex', y='Age', data=df_train)

sns.stripplot(x='Survived', y='Fare', data=df_train)

sns.swarmplot(x='Pclass', y='Age', hue='Survived', data=df_train)

sns.violinplot(x='Sex', y='Age',hue='Survived',data=df_train)

sns.pairplot(df_train, hue='Survived')

df_train.isnull().sum()

df_train.shape

891-687

891-2

891-177

df_train.head()

"""# When to use mean and when to use mod in numerical data impution"""

df_train['Embarked'].value_counts(True)

#Machine learning algo's understand only numeric or numbers- they dont take strings, null values

# Impute missing values for Age, Fare, Embarked
df_train['Age'] = df_train.Age.fillna(df_train.Age.median())
df_train['Fare'] = df_train.Fare.fillna(df_train.Fare.median())
df_train['Embarked'] = df_train['Embarked'].fillna('S')

df_train.dtypes

df_train['Sex'].head()

df_train['Embarked'].value_counts()

df_train[['Sex','Embarked']].head()

df_train = pd.get_dummies(df_train, columns=['Sex', 'Embarked'], drop_first=True)

df_train.isnull().sum()

df_train.columns

df_train.head()

features = ['Pclass', 'Age', 'SibSp', 'Parch', 'Fare', 'Sex_male', 'Embarked_Q', 'Embarked_S']
X = df_train[features]
y = df_train['Survived']

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

df_train.shape

X_train.shape

X_train.tail()

y_train.shape

y_train.tail()

X_test.shape

X_test.head()

y_test.head()

X_train.isnull().sum()

X_train.isnull().sum()

from sklearn.linear_model import LogisticRegression

model = LogisticRegression()
model.fit(X_train, y_train)

y_pred = model.predict(X_test)



from sklearn.metrics import accuracy_score, confusion_matrix,precision_score, recall_score, f1_score


accuracy_score(y_test, y_pred)

confusion_matrix(y_test, y_pred)

precision_score(y_test, y_pred)

recall_score(y_test, y_pred)

f1_score(y_test, y_pred)

y_test_list = list(y_test)
y_pred_list = list(y_pred)

df_results = X_test.copy()
df_results['y_test'] = y_test_list
df_results['y_pred'] = y_pred_list

TP = TN = FP = FN = 0

for i, row in df_results.iterrows():
    actual = row['y_test']
    pred = row['y_pred']
    if actual == 1 and pred == 1:
        TP += 1
    elif actual == 0 and pred == 0:
        TN += 1
    elif actual == 0 and pred == 1:
        FP += 1
    elif actual == 1 and pred == 0:
        FN += 1

total = TP + TN + FP + FN
accuracy = (TP + TN) / total

TP

TN

FP

FN

total

accuracy

precision = TP / (TP + FP)

precision

recall = TP / (TP + FN)

recall

f1_score = 2 * (precision * recall) / (precision + recall)

f1_score

fpr = FP / (FP + TN)

fpr

y_probs = model.predict_proba(X_test)

y_probs

y_probs = y_probs[:, 1]

y_probs



import numpy as np

# Simulate prediction probabilities
#y_probs_full = np.random.dirichlet((1, 2), size=500)
#y_probs = y_probs_full[:, 1]

# Thresholds for grid lines and x-axis labels
thresholds = [0.1, 0.2, 0.3, 0.4, 0.45, 0.5, 0.55, 0.6, 0.7, 0.8, 0.9, 1.0]

plt.figure(figsize=(12, 2.5))
plt.scatter(y_probs, np.zeros_like(y_probs), s=25, color='mediumseagreen', edgecolor='black', alpha=0.7)

# Add light vertical dashed lines at each threshold
for thresh in thresholds:
    plt.axvline(x=thresh, color='gray', linestyle='--', linewidth=0.6, alpha=0.6)

# Set ticks to match threshold values
plt.xticks(thresholds)
plt.title('Titanic Prediction Probabilities (Positive Class)')
plt.xlabel('Predicted Probability (Survived)')
plt.yticks([])
plt.grid(True, axis='x', linestyle='--', linewidth=0.5, alpha=0.5)
plt.xlim(0, 1)
plt.tight_layout()
plt.show()

for t in [0.2, 0.4, 0.5, 0.6, 0.8]:
    y_pred_t = (y_probs >= t).astype(int)
    print(f"--- Threshold: {t} ---")
    print(confusion_matrix(y_test, y_pred_t))

from sklearn.metrics import roc_curve, roc_auc_score

fpr, tpr, thresholds = roc_curve(y_test, y_probs)

fpr

thresholds

tpr

thresholds

auc_score = roc_auc_score(y_test, y_probs)

for t in [0.2, 0.4, 0.5, 0.6, 0.8]:
    y_pred_t = (y_probs >= t).astype(int)
    print(f"--- Threshold: {t} ---")
    print(confusion_matrix(y_test, y_pred_t))

# Youden's J = TPR - FPR
j_scores = tpr - fpr
best_index = j_scores.argmax()
best_threshold = thresholds[best_index]

print("Best Threshold:", best_threshold)

# Plot ROC curve
plt.figure(figsize=(10, 6))
plt.plot(fpr, tpr, label='ROC Curve', color='blue')
plt.plot([0, 1], [0, 1], 'k--', label='Random Model')
plt.xlabel('False Positive Rate (FPR)')
plt.ylabel('True Positive Rate (Recall / TPR)')
plt.title('ROC Curve with Threshold Annotations')

# Annotate selected thresholds
for i in range(0, len(thresholds), 10):  # annotate every 10th threshold to avoid clutter
    plt.annotate(f"{thresholds[i]:.2f}", (fpr[i], tpr[i]), textcoords="offset points", xytext=(5,-5), fontsize=8)

plt.legend()
plt.grid(True)
plt.tight_layout()
plt.show()



# Impute missing values in test data
df_test['Age'] = df_test.Age.fillna(df_test.Age.median())
df_test['Fare'] = df_test.Fare.fillna(df_test.Fare.median())
df_test['Embarked'] = df_test['Embarked'].fillna('S')

df_test = pd.get_dummies(df_test, columns=['Sex', 'Embarked'], drop_first=True)

df_test

# Select same feature columns
features = ['Pclass', 'Age', 'SibSp', 'Parch', 'Fare', 'Sex_male', 'Embarked_Q', 'Embarked_S']
X_submission = df_test[features]

# Predict using trained model
y_submission = model.predict(X_submission)

y_submission

# Create submission DataFrame
submission = pd.DataFrame({
    'PassengerId': df_test['PassengerId'],
    'Survived': y_submission
})

submission

submission.to_csv('submission.csv', index=False)