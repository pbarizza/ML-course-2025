# -*- coding: utf-8 -*-
"""ibmhr.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/19OXbuRqUh_6AGG2qLN3triicodW3K_0U

#Machine Learning Course Assignment#

*Prof: Ladle Patel*

*Student: Pietro Barizza*

*Case study 2: IBM HR Analytics Employee Attrition & Performance*

*Objective*

You are an HR analyst. Your goal is to predict whether an employee is likely to leave the
company using historical HR data. You’ll compare two classification models:
* Logistic Regression
* Decision Tree Classifier
"""

# import libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

"""Q1. Load the dataset and display the first 5 rows."""

# load dataset from github
df = pd.read_csv('https://raw.githubusercontent.com/pbarizza/ML-course-2025/refs/heads/main/assignment/IBMHR_Data.csv')

# explore the dataset
df.head()

"""Q2. What are the key features in this dataset?"""

df.shape

df.columns

df.info()

"""2   BusinessTravel            1470 non-null   object
 3   DailyRate                 1470 non-null   int64
 4   Department                1470 non-null   object
 5   DistanceFromHome          1470 non-null   int64
 6   Education                 1470 non-null   int64
 7   EducationField            1470 non-null   object
 8   EmployeeCount             1470 non-null   int64
 9   EmployeeNumber            1470 non-null   int64
 10  EnvironmentSatisfaction   1470 non-null   int64
 11  Gender                    1470 non-null   object
 12  HourlyRate                1470 non-null   int64
 13  JobInvolvement            1470 non-null   int64
 14  JobLevel                  1470 non-null   int64
 15  JobRole                   1470 non-null   object
 16  JobSatisfaction           1470 non-null   int64
 17  MaritalStatus             1470 non-null   object
 18  MonthlyIncome             1470 non-null   int64
 19  MonthlyRate               1470 non-null   int64
 20  NumCompaniesWorked        1470 non-null   int64
 21  Over18                    1470 non-null   object
 22  OverTime                  1470 non-null   object
 23  PercentSalaryHike         1470 non-null   int64
 24  PerformanceRating         1470 non-null   int64
 25  RelationshipSatisfaction  1470 non-null   int64
 26  StandardHours             1470 non-null   int64
 27  StockOptionLevel          1470 non-null   int64
 28  TotalWorkingYears         1470 non-null   int64
 29  TrainingTimesLastYear     1470 non-null   int64
 30  WorkLifeBalance           1470 non-null   int64
 31  YearsAtCompany            1470 non-null   int64
 32  YearsInCurrentRole        1470 non-null   int64
 33  YearsSinceLastPromotion   1470 non-null   int64
 34  YearsWithCurrManager      1470 non-null   int64
dtypes: int64(26), object(9)
memory usage: 402.1+ KB

[25]
0s
for i, col in enumerate(df.columns):
    print(f"* {i:>2}: {col:<30} -->")
*  0: Age                            --> significative
*  1: Attrition                      --> TARGET VARIABLE
*  2: BusinessTravel                 --> less significative
*  3: DailyRate                      --> significative
*  4: Department                     --> significative
*  5: DistanceFromHome               --> significative
*  6: Education                      --> significative
*  7: EducationField                 --> significative
*  8: EmployeeCount                  --> not significative
*  9: EmployeeNumber                 --> not significative
* 10: EnvironmentSatisfaction        --> highly significative
* 11: Gender                         --> significative
* 12: HourlyRate                     --> significative
* 13: JobInvolvement                 --> significative
* 14: JobLevel                       --> significative
* 15: JobRole                        --> significative
* 16: JobSatisfaction                --> highly significative
* 17: MaritalStatus                  --> significative
* 18: MonthlyIncome                  --> highly significative
* 19: MonthlyRate                    --> significative
* 20: NumCompaniesWorked             --> significative
* 21: Over18                         --> not significative
* 22: OverTime                       --> highly significative
* 23: PercentSalaryHike              --> significative
* 24: PerformanceRating              --> significative
* 25: RelationshipSatisfaction       --> significative
* 26: StandardHours                  --> not significative
* 27: StockOptionLevel               --> significative
* 28: TotalWorkingYears              --> significative
* 29: TrainingTimesLastYear          --> significative
* 30: WorkLifeBalance                --> significative
* 31: YearsAtCompany                 --> significative
* 32: YearsInCurrentRole             --> significative
* 33: YearsSinceLastPromotion        --> significative
* 34: YearsWithCurrManager           --> significative

Overall we can say that OverTime, MontlyIncome, JobSatisfaction, EnvironmentSatisfaction are key feature driving Attrition. We expect their coefficients to be dominant. DistanceFromHome, YearsAtCompany and Age come after, all the rest we expect to contribute in lesser part.

Q3. What is the target variable? What are its possible values?
"""

# count the unique value of Attrition
df['Attrition'].unique()
# alternatively
#df['Attrition'].value_counts()

"""The target variaable is 'Attrition' and has only 2 possible values: 'Yes' or 'No', since this is a binary classification.
Attrition = 'No' --> the employee is unhappy
Attrition = 'Yes' --> the employee is happy

Q4. How many employees left the company vs stayed? (Use value counts on the target variable.)
"""

df['Attrition'].value_counts()

"""237 emploees left and 1233 remains.

Q5. Check for missing values. Are there any?
"""

# checking for missing values
df.isnull().sum()

"""The dataset seems to be complete. no missing values

Q6. Convert categorical columns (like Attrition, Gender, Department, etc.) into numeric form. What encoding method will you use?
"""

df.dtypes

# get the non numerical features
for col in df.columns:
    if df[col].dtype != 'int64':
        print(f"{col}: {df[col].dtype}")

# get the unique values for each of the not numerical features
for col in df.columns:
    if df[col].dtype != 'int64':
        print(f'{col:30}: {df[col].unique()}')

"""The following are binary features.
We use Label Encoding: replace with 0,1 using a map() or replace({'No': 0, 'Yes': 1}) / replace({'Female': 0, 'Male': 1, })
* Attrition
* Gender
* Over18       -->  technically we caould drop this column since it is all 'Y'                 
* OverTime

The remaning feature are multi-categorical.
We use One-Hot Encoding with get_dummies() with drop_first=True to avoid multicollinearity

"""

# label encoding
df['Attrition'] = df['Attrition'].replace({'Yes': 1, 'No': 0})
df['OverTime'] = df['OverTime'].replace({'Yes': 1, 'No': 0})
df['Gender'] = df['Gender'].replace({'Male': 1, 'Female': 0})

# one-hot encoding
df = pd.get_dummies(df, columns=[
    'BusinessTravel',
    'Department',
    'EducationField',
    'JobRole',
    'MaritalStatus'
], drop_first=True)

# drop this colun since not signicative
#df = df.drop('Over18', axis=1)
# see below, question 7

# check if all features are numeric / boolean
df.dtypes

"""Q7. Drop irrelevant columns like EmployeeNumber, Over18, and EmployeeCount. Why?"""

# drop not signicative features
df = df.drop('EmployeeNumber', axis=1)
df = df.drop('EmployeeCount', axis=1)
df = df.drop('Over18', axis=1)

"""These three features are not significative. EmployeeNumber since an ID, EmployeeCount a count and Over18 since all values are the same 'Y'

Q8. Select meaningful features for prediction (at least 8–10). Which ones did you choose and why?
"""

features = ['Age', 'DailyRate', 'DistanceFromHome', 'Education',
       'EnvironmentSatisfaction', 'Gender', 'HourlyRate', 'JobInvolvement',
       'JobLevel', 'JobSatisfaction', 'MonthlyIncome', 'MonthlyRate',
       'NumCompaniesWorked', 'OverTime', 'PercentSalaryHike',
       'PerformanceRating', 'RelationshipSatisfaction', 'StandardHours',
       'StockOptionLevel', 'TotalWorkingYears', 'TrainingTimesLastYear',
       'WorkLifeBalance', 'YearsAtCompany', 'YearsInCurrentRole',
       'YearsSinceLastPromotion', 'YearsWithCurrManager',
       'BusinessTravel_Travel_Frequently', 'BusinessTravel_Travel_Rarely',
       'Department_Research & Development', 'Department_Sales',
       'EducationField_Life Sciences', 'EducationField_Marketing',
       'EducationField_Medical', 'EducationField_Other',
       'EducationField_Technical Degree', 'JobRole_Human Resources',
       'JobRole_Laboratory Technician', 'JobRole_Manager',
       'JobRole_Manufacturing Director', 'JobRole_Research Director',
       'JobRole_Research Scientist', 'JobRole_Sales Executive',
       'JobRole_Sales Representative', 'MaritalStatus_Married',
       'MaritalStatus_Single']

"""I have chosen all of them, since all contribute with different weights to a better accuracy

Q9. Split the dataset into feature matrix X and target variable y
"""

# extract features and target
# Attrition is our target
X = df[features]
y = df['Attrition']
X.sample(5)

y.sample(5)

"""Q10. Perform train-test split (e.g., 80% training, 20% testing)."""

# train-test split at 80/20
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# check the shape
X_train.shape

X_test.shape

y_train.shape

y_test.shape

"""Q11. Apply feature scaling using StandardScaler. Why is this important for Logistic Regression?"""

from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

X_train_scaled

X_test_scaled

"""Scaling is important since the different features are measure in different unit of measurement, but sklearn (and in general any algorithm) is not aware of the unit. additionally features should be comparable, otherwise the gradients vanish or explode

#Modeling & Evaluation#

Q12. Train a Logistic Regression model and make predictions.
"""

# Logistic regresson
from sklearn.linear_model import LogisticRegression


# training
# note, since the target is categorical, no need to scale the target
log_reg = LogisticRegression()
log_reg.fit(X_train_scaled, y_train)

# predict on the test split
y_pred_lr = log_reg.predict(X_test_scaled)

y_pred_lr

"""Q13. Train a Decision Tree Classifier with a max_depth=4 and make predictions."""

# Decision Tree Classifier
from sklearn.tree import DecisionTreeClassifier

# training
# note Decision tree works on Gini inpurity or Cross Entropy, not on gradients
# so no need of scaling the data
dt_clf = DecisionTreeClassifier(max_depth=4, random_state=42)
dt_clf.fit(X_train, y_train)

# predict on the test split
y_pred_dt = dt_clf.predict(X_test)

y_pred_dt

results_df = pd.DataFrame({
    'y_test': y_test,
    'y_pred_lr': y_pred_lr,
    'y_pred_dt': y_pred_dt,
    'lr_correct': y_pred_lr == y_test,
    'dt_correct': y_pred_dt == y_test
})

results_df.head()

"""Q14. Evaluate both models using:
* Accuracy
* Confusion Matrix
* Precision, Recall, F1 Score
* ROC AUC Score
Which model performs better overall?
"""

from sklearn.metrics import accuracy_score, classification_report
from sklearn.metrics import confusion_matrix, roc_auc_score, roc_curve

# evaluate Logistic Regression
print('\nLogist Regression')
print('Accuracy:', accuracy_score(y_test, y_pred_lr))
print('\nConfusion Matrix:\n', confusion_matrix(y_test, y_pred_lr))
print('\nClassification Report:\n', classification_report(y_test, y_pred_lr))
y_pred_proba_lr = log_reg.predict_proba(X_test_scaled)[:, 1]
print('ROC AUC Score:', roc_auc_score(y_test, y_pred_proba_lr))

print('\nDecision Tree')
print('Accuracy:', accuracy_score(y_test, y_pred_dt))
print('\nConfusion Matrix:\n', confusion_matrix(y_test, y_pred_dt))
print('\nClassification Report:\n', classification_report(y_test, y_pred_dt))
y_pred_proba_dt = dt_clf.predict_proba(X_test)[:, 1]
print('ROC AUC Score:', roc_auc_score(y_test, y_pred_proba_dt))

from sklearn.metrics import precision_score, recall_score, f1_score
# Logistic Regression metrics
lr_accuracy = accuracy_score(y_test, y_pred_lr)
lr_precision = precision_score(y_test, y_pred_lr)
lr_recall = recall_score(y_test, y_pred_lr)
lr_f1 = f1_score(y_test, y_pred_lr)
lr_roc_auc = roc_auc_score(y_test, y_pred_proba_lr)

# Decision Tree metrics
dt_accuracy = accuracy_score(y_test, y_pred_dt)
dt_precision = precision_score(y_test, y_pred_dt)
dt_recall = recall_score(y_test, y_pred_dt)
dt_f1 = f1_score(y_test, y_pred_dt)
dt_roc_auc = roc_auc_score(y_test, y_pred_proba_dt)

# tabular format for better comparison
metrics_df = pd.DataFrame({
    'Accuracy': [lr_accuracy, dt_accuracy],
    'Precision': [lr_precision, dt_precision],
    'Recall': [lr_recall, dt_recall],
    'F1 Score': [lr_f1, dt_f1],
    'ROC AUC Score': [lr_roc_auc, dt_roc_auc]
}, index=['Logistic Regression', 'Decision Tree'])

metrics_df

"""**Results**:

*   **Accuracy:** Logistic Regression accuracy (0.878) > Decision Tree accuragy (0.854). LR performed better

*   **Precision:** Logistic Regression precision (0.548) >> Decision Tree precision (0.250). igher precision is important when minimizing false positives is crucial

*   **Recall (for class 1 - Attrition 'Yes'):** Logistic Regressionrecall (0.436) >> Decision Tree recall (0.051). Higher recall is important when minimizing false negatives is crucial (fail to identify an employee who is likely to leave).

*   **F1 Score (for class 1 - Attrition 'Yes'):** Logistic Regression F1 Score (0.486) >> Decision Tree F1 score (0.085). This means overall performance ofr Logistinc Regression in predicting.

*   **ROC AUC Score:** Logistic Regression ROC AUC Score (0.790) > Decision Tree ROC AUC Score (0.639).  Logistic Regssion better discriminates


**Logistic Regression model performs significantly better** than the Decision Tree.

#Visual Analysis#

Q15. Plot the confusion matrix for both models. What do they tell you?
"""

# Confusion Matrix for Logistic Regression
cm_lr = confusion_matrix(y_test, y_pred_lr)
plt.figure(figsize=(6, 4))
sns.heatmap(cm_lr, annot=True, fmt='d', cmap='Blues', xticklabels=['Stayed', 'Left'], yticklabels=['Stayed', 'Left'])
plt.title('Confusion Matrix - Logistic Regression')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.show()

# Confusion Matrix for Decision Tree
cm_dt = confusion_matrix(y_test, y_pred_dt)
plt.figure(figsize=(6, 4))
sns.heatmap(cm_dt, annot=True, fmt='d', cmap='Blues', xticklabels=['Stayed', 'Left'], yticklabels=['Stayed', 'Left'])
plt.title('Confusion Matrix - Decision Tree')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.show()

"""* **Logistic Regression:**
    *   TN: 241  staying employees
    *   FP: 14 predicted as leaving when they stay
    *   FN: 22 predicted as staying when they left
    *   TP: 17 employees leaving.

* **Decision Tree:**
    *   TN: 249  staying employees
    *   FP: 6 predicted as leaving when they stay
    *   FN: 37 predicted as staying when they left
    *   TP: 2 employees leaving.


**Conclusion:**

Logistic Regression model is better at identifying employees who are likely to leave (high TP and low FN)

The Decision Tree has a very high number of FN, meaning it misses employees who actually leave.

Q16. Plot the ROC Curve for both models. Which has a better AUC?
"""

from sklearn.metrics import roc_curve, auc

# logistic regression ROC/AUC
fpr_lr, tpr_lr, thresholds_lr = roc_curve(y_test, y_pred_proba_lr)
roc_auc_lr = auc(fpr_lr, tpr_lr)

# decision tree ROC/AUC
fpr_dt, tpr_dt, thresholds_dt = roc_curve(y_test, y_pred_proba_dt)
roc_auc_dt = auc(fpr_dt, tpr_dt)

# plot
plt.figure(figsize=(8, 6))
plt.plot(fpr_lr, tpr_lr, color='green', lw=2, label='Logistic Regression (AUC = %0.2f)' % roc_auc_lr)
plt.plot(fpr_dt, tpr_dt, color='red', lw=2, label='Decision Tree (AUC = %0.2f)' % roc_auc_dt)
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve')
plt.legend(loc='lower right')
plt.show()

"""*   **Logistic Regression AUC = 0.79**
*   **Decision Tree AUC = 0.64**

The **Logistic Regression model has a better AUC** (0.79) compared to the Decision Tree model (0.64).
This means that Logistic Regression has an higher ability to distinguish between FP and TP

#Interpretation#

Q17. What are the most important features in predicting attrition (use .coef_ for Logistic, .feature_importances_ for Decision Tree)?
"""

# print LR coefficients
log_reg.coef_

# print DT features
dt_clf.feature_importances_

# LR: flatten the array into a series and order by absolute value descending
coef = pd.Series(log_reg.coef_[0], index=X.columns)
coef = coef.abs().sort_values(ascending=False)
print('Logistic Regression coefficients:')
coef.head(10)

# DT: flatten the array into a series and order by value descending
fea_imp = pd.Series(dt_clf.feature_importances_, index=X.columns)
fea_imp = fea_imp.sort_values(ascending=False)
print('Decision Tree')
fea_imp.head(10)

"""Q18. What does the Logistic Regression model tell you about the odds of attrition for certain features like OverTime or JobSatisfaction?"""

coef[['JobSatisfaction', 'OverTime']]

"""* JobSatisfaction is negative, means that the more it increase the more descrease the probability the employee leave

* OverTime has a large positive number which means the more the OverTime increase the more the employee leave

Q19. What business insights can HR managers gain from this model?

The analysis tells the HR manager that he should consider the key drivers for attrition:
* OverTime, MonthlyIncome, JobLevel JobRole_Laboratory_Technician	 and BusinessTravel_Travel_Frequently
* take actions to reduce OverTime
* implement a retention policy
* concentrate on some roles like Technicial
* and work on a policy for frequent business traveller employees

Q20. Suggest 2-3 ways the company could reduce attrition based on your findings.

The company should focus on the follogin key aspects:
1. reduce Overtime

2. increase compensation (or at least align to the competitor average

3. work on the job satisfaction, especially for the tehcnical roles and the frequent business traveller.
"""